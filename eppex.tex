% In this chapter:
% - introduction of eppex
% -- design goals
% -- distinction from legacy phrase-extract tools
% - implementation details
% -- Murmur hash, boost pools, std c++11 hash tables, indexed storages, gzipped I/O

\chapter{Eppex}
\label{chap:eppex}

\Eppex{} is phrase pairs extraction and scoring tool capable of obtaining approximate
frequency counts of extracted phrase pairs by using Lossy Counting algorithm
(thus the name \eppex{}, an acronym for \emph{epochal phrase pairs extraction}).
It is designed to be an alternative to standard phrase extraction and scoring tools that
are shipped with Moses, implementing most of the functionality of steps 5 and 6 of
\emph{train-model.perl} script.
\Eppex{} input and output interface is fully compatible with those of the replaced tools
and \eppex{} in fact is intended to be invoked from within the Moses training script itself
by passing specific parameters.

\Eppex{} differs from its core counterparts in one important aspect: during its runtime
only physical memory is utilized, no temporary files are stored on disk as with \emph{extract}
and \emph{score} tools.
The goal is to make \eppex{} a faster alternative, aiming at environments with plenty of RAM.
Benchmarking of time/memory trade-offs was fundamental part of this work and the results are
thoroughly examined in \Cref{chap:results}.

\Eppex{} memory demands may be limited by setting more restrictive support and error thresholds
for Lossy Counting, but aggressive pruning may lead to loss of phrase table quality --
experimentally evaluated trade-offs are also discussed in \Cref{chap:results}.

This chapter is fully devoted to technical aspects of implementation and it expects the reader
to be familiar with the basics of programming and the C++ programming language, including
a basic knowledge of Standard Template Library (STL).
Instructions on how to install \eppex{} on Linux-based operating system are given in
\Aref{chap:installation}, usage instructions are given in \Aref{chap:usage}.

\section{Design goals}

% TODO: Info on GCC versions with std::unordered_ implementation.

% TODO: Mention implementation tricks and tweaks:
% Murmur hash, boost pools, std c++11 hash tables, indexed storages, gzipped I/O

% What and why is a target platform?
\Eppex{} is implemented as a command-line program and, as indicated above, it is written in C++.
As the primary development platform for Moses is Linux\footurl{http://www.statmt.org/moses/?n=Development.GetStarted},
\eppex{} adheres to the same philosophy.
It has been developed and tested on desktop version of Ubuntu 12.04 LTS with GCC 4.6.3
and server version of Ubuntu 10.04 LTS with GCC 4.4.3 installed. % TODO: Check server version.
Nevertheless, considerable effort has been taken to make the implementation as cross-platform
compatible as possible.

% 64-bit or 32-bit?
\Eppex{} is intended to be run on 64-bit machines, but this is rather a matter of fact than
a requirement: to process a parallel corpus of reasonable size, \eppex{} will in typical
setting require much more memory than 32-bit environments can provide\footnote{In 32-bit
environment the virtual address space holds no more than $2^{32}$ addresses, so at maximum
4,294,967,296 bytes (4~GB) of memory are utilizable. Workarounds exist, but they might be
considered unfeasible nowadays, as 64-bit architecture is well established.} (see \Cref{chap:results}
for exact numbers).
Therefore, although not tested, \eppex{} should run as smoothly on 32-bit machine as it runs
on 64-bit, but the amount of input data that it will manage to process will have to be decent
or aggressive pruning will have to be undertaken.

% Why C++?
C++ is a programming language that offers a wide range of optimization techniques to
tune up both the execution speed and memory requirements of a program.
Both aspects are important to us, but memory usage optimization is our primary concern,
since the execution speed, when compared to legacy tools, is implicitly boosted by the algorithm
we employ and the fact that we keep all temporary data in the computer memory instead of disk.

\section{Implementation analysis and description}

Effective program design consist of two main parts that are strictly related:
a good analysis of the problem along with the choice of the platform and programming language
should be followed by a fitting implementation that properly uses all the programming techniques
and methods available in the selected language.

During the program runtime the input data are processed in order to establish frequency counts
necessary to compute the phrase pair scores and print the complete phrase translation table.
This requires the phrase pairs to be extracted and kept in the memory along with the frequency
and maximum error for lossy counting -- essentially, a set of triples $(e, f, \Delta)$ is
to be maintained.\footnote{Recall the data structure $D$ introduced in \Cref{chap:lossy-counting}.}
This data account for most of the memory required during the runtime, therefore their effective
representation is mission-critical.

\subsection{sizeof(integer)}

Both frequency count and maximum error are plain unsigned integers, so at first it might seem
there is nothing that can be possibly done about their optimization.
However, it will be unwise to just declare them both as \verb|size_t| or \verb|unsigned int|.
First, these datatypes can have different sizes on different platforms (typically, \verb|size_t| is
4 bytes long on 32-bit, but 8 bytes long on 64-bit).
Second, it is important to realize that by processing real life data we may never need as much
space as some integer types provide and saving even few bytes per item can lead to gigabytes saved
in total.

To solve both issues, we base the definitions of crucial datatypes on definitions of cross-platform
fixed-size integer types from Boost stdint library: 4 bytes allow to store unsigned values up to
$2^{32} \approx 4.3 \times 10^9$ and this is definitely enough to store our frequencies\footnote{There
is no parallel corpus yet with billions of parallel sentences, therefore it is safe to expect no phrase
pair will occur billion times.}; 1 byte allow to store values up to 255 and this is enough to store
the maximum error values -- they are always less than the number of epochs in a single run and in our
settings having more than just a few epochs led to pruning that already hurt too much.
% TODO: Check library name and URL.

% Object members data alignment issues

% Indexed strings storage

% "Copying" phrases between extraction and scoring

\section{Words, phrases, alignments}

% Types of objects stored:
% - words, phrases, alignments

During the program runtime, a multitude of objects of following three types has to be
kept in memory:
\begin{itemize}
  \item word -- a sequence of characters (bytes)
  \item phrase -- a sequence of words
  \item alignment -- a sequence of pairs of indexes
\end{itemize}

The word is just a string.

\subsection{C-string vs. std::string}
% Why had we used C-string instead of std::string.

Unlike Java, C and C++ have no fundamental data type for strings, instead they have to be
stored as an array of \verb|chars|.
Such string handling is obviously too low-level for most modern applications,
which are mainly about string processing, so STL creators came to help and designed several
\emph{string} classes that mimic behavior of ordinary data types \citep[Chapter 11]{josuttis:stl}:
STL strings may be copied, assigned and compared like any other fundamental type,
without the programmer being worried about the internal memory allocations and deallocations.
Because both approaches are very often used side by side, there exists usual terminology to
distinguish between them:
the arrays of characters are called \emph{C-like-strings} (or shortly \emph{C-strings}) and
STL string classes are just \emph{strings} (sometimes labeled \emph{std::string} after the
most commonly used class).

From the memory management standpoint, it turns out, that any \emph{std::string} implementation
has bigger memory demands than old plain C-string.
This is expectable: the string class has to provide more flexible interface and does all
the internal memory management by itself. Depending on particular implementation, it might
store the size of the string, store the capacity of allocated memory, do the reference counting
and more \citep[Item 15]{meyers:effectivestl}.
This is why we backed off to use C-strings to store string data in \eppex{}.
The reference counting feature seems to be useful for our phrase-counting problem,
but not every STL implementation has it.
In addition, we designed a string referencing solution more tailored to our needs.

\subsection{Persistence and memory pooling}

% Indexed strings storage (and memory pools)

\section{Unordered sets}

The recent C++ standard\footnote{ISO/IEC 14882:2011}, informally marked as C++11, standardizes
a new type of containers, that were in fact already part of almost every implementation of STL,
but the lack of standard definition resulted in slight differences across various implementations.
The \emph{unordered_set} and \emph{unordered_map} containers are well known to almost every
programmer, although usually they are referred to under a different name, as \emph{hash tables}.

\subsection{Murmur hash}

\section{Compressed I/O}
% TODO: Is it worth mentioning? Maybe move to Usage part?

\Eppex{} can read/write directly from/to gzipped files, the same way legacy \emph{phrase-extract}
tools does.
This option allows to save a significant amount of disk space, as a typical phrase table will be
3-4 times smaller when gzipped. % TODO: Proof-check the guess.
Moreover, in environments when disks are under heavy load (shared computation servers are often
the case), it may even speed up the whole I/O process.

Our implementation simply reuses the respective library shipped with Moses source code,
as it is cleanly designed and easy to include.
