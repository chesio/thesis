\chapter{Results}
\label{chap:results}

\setlength{\epigraphwidth}{1.0\textwidth}
\epigraph{The closer a machine translation is to a professional human translation, the better it is.}{--- Papineni et al., BLEU: a Method for Automatic Evaluation of Machine Translation}

\section{Cs-En dataset}
\label{sec:cs-en-results}

We perform 14 experimental phrase table extractions for Cs-En dataset,
the comprehensive list is presented by \Tref{cs-en-wmt13-scenarios}.
We included one more optimized baseline with 8 cores, because the difference in
wall clock time necessary to construct the phrase table between runs with 4 and 8 cores
was considerable.
Sorting processes in both optimized baselines were given 18~GB of memory, so the virtual
peak of entire pipeline reached approximately the same value as in case of \eppex{}
run with no pruning.

% Cs-En: description and parameters of experiments
\begin{table}[ht]
\centering
\begin{tabular}{ r p{10cm} }
name & description and parameters \\
\hline
\hline
def-base        & Standard Moses pipeline with no special parameters \\
multi-base      & Standard Moses pipeline with \verb|--cores 4| \\
comp-base       & Standard Moses pipeline with \verb|--sort-compress gzip| and \verb|--cores 4| \\
opt-base        & Standard Moses pipeline with \verb|--sort-buffer 18G|, \verb|--sort-compress gzip| and \verb|--cores 4| \\
opt-c8-base     & Standard Moses pipeline with \verb|--sort-buffer 18G|, \verb|--sort-compress gzip| and \verb|--cores 8| \\
\hline
eppex zero      & \eppex{} set to no pruning and \verb|--GZOutput| option \\
eppex def.      & \eppex{} with \verb|--limits| set to \verb|1-3:0:1,4-5:1:4,6-7:4:8| and \verb|--GZOutput| option \\
eppex 0:n       & \eppex{} with \verb|--limits| set to \verb|1:0:1,2:0:2,...,7:0:7| and \verb|--GZOutput| option \\
eppex 0:n+1     & \eppex{} with \verb|--limits| set to \verb|1:0:2,2:0:3,...,7:0:8| and \verb|--GZOutput| option \\
eppex 1:n+1     & \eppex{} with \verb|--limits| set to \verb|1:1:2,2:1:3,...,7:1:8| and \verb|--GZOutput| option \\
\hline
sigfilter a-e   & baseline followed by significance filtering with pruning threshold $\alpha - \epsilon$ \\
sigfilter a+e   & baseline followed by significance filtering with pruning threshold $\alpha + \epsilon$ \\
sigfilter 30 a+e  & baseline followed by significance filtering with cutoff limit of 30 and pruning threshold $\alpha + \epsilon$ \\
sigfilter 30    & baseline followed by significance filtering with cutoff limit of 30 \\
\hline
\hline
\end{tabular}
\caption{\label{cs-en-wmt13-scenarios}
List of various experiments and their settings for Cs-En setup, "eppex~def." is shortcut for \emph{eppex defensive}.}
\end{table}

The \emph{eppex zero} experiment is performed to establish the maximum memory demands of \eppex{}
for the input data of a given size.
The \emph{eppex defensive} experiment has the positive and negative limits set to achieve the same
level of pruning as the \emph{eppex 1-in} experiment that performed very well in 2011 experiments.
The remaining \eppex{} experiments have a separate Lossy Counter set for every phrase length:
the negative limit is the same for all instances, but the positive limit is set in correspondence
to a phrase length to allow for a bigger estimation errors in the case of longer phrase pairs.

\subsection{Translation phrase table size and quality}

\Tref{cs-en-wmt13-pt-size-and-bleu} presents the phrase table sizes and BLEU scores for all
distinct phrase tables created in our experiments.
Despite that the phrase table sizes are very different, with the most pruned phrase table being
only $1/13$ size of the baseline, the achieved BLEU scores are very tight and the difference
between the best and the worst score is only 0.66~point in the case of \emph{wmt-12} test data
and 0.61~point in the case of \emph{wmt-13} test data.

% Cs-En: phrase tables sizes and BLEU scores
\begin{table}[ht]
\centering
\begin{tabular}{ | c | c c | c c | }
\hline
 & \multicolumn{2}{|c|}{final phrase table size} & \multicolumn{2}{|c|}{BLEU score} \\
experiment & phrase pairs & .gz file size & wmt-12 & wmt-13 \\
\hline
\hline
baseline          & 336.0~M & 8.8~GB & 0.2327 & 0.2583 \\
sigfilter 30      & 301.9~M & 8.2~GB & 0.2312 & 0.2562 \\
sigfilter a-e     & 203.1~M & 5.9~GB & 0.2301 & 0.2560 \\
eppex def.        & 109.8~M & 2.7~GB & \textbf{0.2338} & \textbf{0.2598} \\
eppex 0:n         &  86.2~M & 2.3~GB & 0.2324 & 0.2586 \\
sigfilter a+e     &  70.0~M & 1.9~GB & 0.2321 & 0.2559 \\
eppex 0:n+1       &  67.9~M & 1.8~GB & 0.2304 & 0.2561 \\
sigfilter 30 a+e  &  60.2~M & 1.7~GB & 0.2305 & 0.2563 \\
eppex 1:n+1       &  25.7~M & 0.7~GB & 0.2272 & 0.2537 \\
\hline
\end{tabular}
\caption{\label{cs-en-wmt13-pt-size-and-bleu}
Phrase table sizes and BLEU scores for the various experiments of Cs-En setup.}
\end{table}

The \emph{eppex defensive} experiment again proved to be very competitive:
the phrase table has only $1/3$ of size of the baseline,
but the BLEU score is actually better for the both test sets (although not significantly).
On the other hand, pruning of all single occurring phrase pairs in the \emph{eppex 1:n+1}
experiment resulted in the worst score on both sets, and seems to be already
too harsh for the Cs-En setup.

Interestingly, there is no clear differentiation of what was the best \emph{sigfilter}
configuration: especially, in the case of \emph{wmt-13} test data all the scores
happen to occur within a tiny range of $[0.2559, 0.2563]$, despite the phrase table sizes
differs significantly, from 60.2~M to 301.9~M of phrase pairs.

\subsection{Memory and time requirements}

\Tref{cs-en-wmt13-time-benchmarks} presents the amount of time necessary to finish
phrase table extraction with various systems and their configurations.

% Cs-En: baseline and eppex wall clock and CPU time values
\begin{table}[ht]
\centering
\begin{tabular}{ | c | r r | r r | r r | }
\hline
 & \multicolumn{2}{|c|}{total time} & \multicolumn{2}{|c|}{extraction} & \multicolumn{2}{|c|}{scoring} \\
experiment & wall & CPU & wall & CPU & wall & CPU \\
\hline
\hline
def-base      & 15.6 & 15.5 & 7.1 & 6.5 & 8.5 & 9.0 \\
multi-base    & 10.4 & 19.4 & 4.9 & 6.7 & 5.5 & 12.7 \\
comp-base     & 10.6 & 25.4 & 4.1 & 11.3 & 6.4 & 14.1 \\
opt-base      & 8.3 & 19.9 & 2.6 & 7.0 & 5.6 & 13.0 \\
opt-c8-base   & 7.0 & 20.7 & 2.3 & 7.2 & 4.7 & 13.6 \\
eppex zero    & 2.9 & 2.9 & -- & -- & -- & -- \\
\hline
eppex def.    & 1.6 & 1.6 & -- & -- & -- & -- \\
eppex 0:n     & 1.5 & 1.5 & -- & -- & -- & -- \\
eppex 0:n+1   & 1.4 & 1.4 & -- & -- & -- & -- \\
eppex 1:n+1   & 1.2 & 1.2 & -- & -- & -- & -- \\
\hline
\end{tabular}
\caption{\label{cs-en-wmt13-time-benchmarks}
Wallclock times and CPU usage values (in hours) of the phrase table
construction for the various experiments of Cs-En setup.}
\end{table}

Even with no pruning \eppex{} is capable of doing the phrase table construction more
than twice as fast as the most challenging baseline (and using 7 times less CPU time).
When compared to the default baseline the difference is even more pronounced with \eppex{}
being 5~times as fast.

From the comparison of the default and multi-core baseline it seems clear that whenever there
is a possibility to employ multiple cores it should be taken: just by running with 4 cores
the baseline execution time has been cut to $2/3$.
Doubling number of cores from 4 to 8 in optimized experiments resulted in further reduction
of execution time, although not as significant (by 15\%).

An important observation is that adding only the option to make \texttt{sort} program gzip
its temporary data, did not help to decrease the total execution time.
More precisely, it did help in phrase extraction step (ca. $-0.8~h$), but did the very opposite
in scoring step (ca. $+0.9~h$), so the overall impact on the total wall clock time was eventually
a bit negative (ca. $+0.2~h$).
A reasonable explanation for such, perhaps unexpected, behavior stems from the fact that in phrase
extraction step both phrase table halves are sorted simultaneously, whereas in scoring step
only indirect half is sorted:
apparently, in our environment forcing \texttt{sort} to gzip its temporary data makes it run
slower when there are no other processes accessing the disk (as in the scoring step), but reducing
the disk access by the same means when two similar sort tasks run simultaneously can benefit
in both of them finishing faster (as in the phrase extraction step).
This explanation might be further supported by the fact that a lot of \texttt{sort} temporary
data gzipping took place in \emph{comp-base} experiment, because the striking increase of CPU time
consumption can only be attributed to this extra gzipping: % TODO: Reformulate, unreadable.
phrase extraction required almost 4.5 CPU hours more, scoring required almost 1.5 CPU hours
more.\footnote{Given that there are two and one sorting processes, one could expect the ratio
4.5:1.5 of additional CPU time to be closer to 2:1, but after phrase extraction phrase table halves
contain every phrase pair occurrence, whereas after scoring they contain only unique phrase pairs,
so the size of data to sort is rather close to 3:1 than 2:1 ratio.}
The similar conclusions might be made also by examination of partial wall clock times of \emph{multi-base}
and \emph{opt-base} experiments: while the phrase extraction time fell down from 4.9~hours to 2.6~hours
(i.e. almost to $1/2$), the scoring time jumped up a bit from 5.5~hours to 5.6~hours.
Thus, even the significantly increased sorting buffer managed only to neutralize the negative impact of
temporary data compression on wall clock time of scoring step, but in the same time it further pronounced
the positive impact of the same settings on phrase extraction step.

However, to put things in a wider perspective, we believe that the option to compress temporary data of
\texttt{sort} routine has been introduced in order to limit the peak usage of disk space, which may
otherwise pose a limiting factor in some environments, as the figures presented in the following text
demonstrate.

\Tref{cs-en-wmt13-vm-and-disk-usage-peaks} illustrates both memory and disk space demands of the baseline
and \eppex{} experiments.

% Cs-En: virtual memory and disk usage peaks
\begin{table}[ht]
\centering
\begin{tabular}{ | c | r l | r | }
\hline
 & \multicolumn{2}{|c|}{VM peak} & \\
experiment & size & step & du peak \\
\hline
\hline
def-base       &  2.0~GB &    scoring & 206.7~GB \\
multi-base     &  6.2~GB &    scoring & 213.5~GB \\
comp-base      &  6.2~GB &    scoring &  43.4~GB \\
opt-base       & 36.2~GB & extraction &  42.8~GB \\
opt-c8-base    & 36.2~GB & extraction &  42.8~GB \\
eppex zero     & 36.8~GB &      eppex &   8.8~GB \\
\hline
eppex def.     & 18.1~GB &      eppex &   2.7~GB \\
eppex 0:n      & 10.5~GB &      eppex &   2.2~GB \\
eppex 0:n+1    &  8.4~GB &      eppex &   1.8~GB \\
eppex 1:n+1    &  9.6~GB &      eppex &   0.7~GB \\
\hline
\end{tabular}
\caption{\label{cs-en-wmt13-vm-and-disk-usage-peaks}
Virtual memory and disk usage peaks of the phrase table construction for various experiments of "Cs-En" setup.}
\end{table}

The default baseline experiment had the lowest memory demands from all experiments, it needed only 2~GB
of memory to finish.
With non-default settings the memory consumption tripled when multiple cores were utilized (in \emph{multi-base}
and \emph{comp-base} experiments), except for cases when it was dominated by the size of buffer dedicated
to \texttt{sort} routine (in optimized experiments).

\Eppex{} memory demands are largely dependent on the amount of pruning requested: with \emph{zero}
pruning almost 37~GB of memory was consumed, mild \emph{defensive} pruning required only half as much
memory and harsh \emph{1:n+1} pruning only $1/4$ (but still almost 10~GB).
The comparison of VM peaks and phrase table sizes of \emph{eppex 0:n+1} and \emph{eppex 1:n+1}
experiments confirms the findings from \Sref{sec:lossy-counting-applicability}:
because of the harsher limits, \emph{eppex 1:n+1} produced a half as big phrase table as \emph{eppex 0:n+1},
but since it had a smaller estimation error, it required 15\% more memory.

The disk usage peak exceeded 200~GB in the baseline experiments without compression of
\texttt{sort} temporary data, with the compression it lowered to approximately 40~GB
(notably still above the memory peak of \eppex{} with no pruning).
As noted before, \eppex{} produces no temporary data, therefore in all experiments the
disk usage peaks strictly copied the size of the produced phrase tables.

Finally, \Tref{cs-en-wmt13-sigfilter-runtime-benchmarks} presents the runtime benchmarking
values for different runs of significance filtering.
Even the simple histogram pruning required more time than any \eppex{} run with nonzero
pruning limits.\footnote{This is partially due a design flaw in the \texttt{sigfilter} tool:
the SALM-indexed corpus is always required to proceed, even though it is not necessary in
the case of histogram pruning. The unnecessary SALM indexing accounts for a large part
of the reported wall clock time.}
On the other hand, the memory demands of \emph{sigfilter}, although considerable, were
always below those of \eppex{}.

% Cs-En: sigfilter runtime requirements
\begin{table}[ht]
\centering
\begin{tabular}{ | c | r r | r l | }
\hline
 & \multicolumn{2}{|c|}{time} & \multicolumn{2}{|c|}{VM peak} \\
experiment & wall & CPU & size & step \\
\hline
\hline
sigfilter a-e     & 10.2~h & 11.3~h & 6.7~GB & filtering \\
sigfilter a+e     & 9.9~h & 10.6~h & 6.8~GB & filtering \\
sigfilter 30 a+e  & 8.1~h & 8.7~h & 6.7~GB & filtering \\
sigfilter 30      & 2.5~h & 3.4~h & 2.7~GB & indexing \\
\hline
\end{tabular}
\caption{\label{cs-en-wmt13-sigfilter-runtime-benchmarks}
The complete benchmarking figures for various settings of \emph{sigfilter} in Cs-En setup:
wallclock time, CPU usage value and virtual memory peak with the step, in which it occurred.}
\end{table}

\section{Fr-En dataset}
\label{sec:fr-en-results}

\Tref{fr-en-80-scenarios} presents the list of all the experimental phrase table extraction
performed on the Fr-En dataset.

% Fr-En: description and parameters of experiments
\begin{table}[ht]
\centering
\begin{tabular}{ r p{10cm} }
name & description and parameters \\
\hline
\hline
opt-base      & Standard Moses pipeline with \verb|--sort-buffer 100G|, \verb|--sort-compress gzip| and \verb|--cores 4| \\
opt-c8-base   & Standard Moses pipeline with \verb|--sort-buffer 100G|, \verb|--sort-compress gzip| and \verb|--cores 8| \\
eppex zero    & \eppex{} set to no pruning and \verb|--GZOutput| option \\
eppex def.    & \eppex{} with \verb|--limits| set to \verb|1-3:0:1,4-5:1:4,6-7:4:8| and \verb|--GZOutput| option \\
eppex zero-n  & \eppex{} with \verb|--limits| set to \verb|1:0:1,2:0:2,...,7:0:7| and \verb|--GZOutput| option \\
eppex 1:n+1   & \eppex{} with \verb|--limits| set to \verb|1:1:2,2:1:3,...,7:1:8| and \verb|--GZOutput| option \\
eppex 2:n+2   & \eppex{} with \verb|--limits| set to \verb|1:2:3,2:2:4,...,7:2:9| and \verb|--GZOutput| option \\
\hline
\hline
\end{tabular}
\caption{\label{fr-en-80-scenarios}
List of various experiments and their settings for "Fr-En" setup.}
\end{table}

In the case of baseline experiments, we had attempted all the configurations mentioned
in \Sref{sec:baseline-experiments}, but managed to only finish the optimized ones.
The non-optimized attempts usually died in the middle of sorting with \texttt{sort} complaining
about missing temporary files.
We did not investigate the exact reason, but our raw guess is that the number of temporary
files reached some system-imposed limit, as there were thousands of temporary files left in
the working directory after the process died.

The evaluated \eppex{} configurations are basically the same as in the case of Cs-En setup,
we only included an additional, harsher configuration \emph{eppex 2:n+2}.

\subsection{Translation phrase table size and quality}

\Tref{fr-en-pt-size-and-bleu} presents phrase table sizes and BLEU scores for all
distinct phrase tables created in our experiments.

% Fr-En: phrase tables sizes and BLEU scores
\begin{table}[ht]
\centering
\begin{tabular}{ | c | r r | c c | }
\hline
 & \multicolumn{2}{|c|}{final phrase table size} & \multicolumn{2}{|c|}{BLEU score} \\
experiment & phrase pairs & .gz file size & wmt-12 & wmt-13 \\
\hline
\hline
baseline          & 1782.0~M & 42.5~GB & 0.2860 & 0.2958 \\
sigfilter 30      & 1470.8~M & 35.9~GB & 0.2849 & 0.2964 \\
sigfilter a-e     &  811.4~M & 21.0~GB & 0.2845 & 0.2953 \\
eppex def.        &  463.4~M & 10.6~GB & \textbf{0.2867} & 0.2950 \\
sigfilter a+e     &  329.5~M &  8.4~GB & 0.2866 & \textbf{0.2977} \\
eppex zero-n      &  283.2~M &  7.0~GB & 0.2841 & 0.2950 \\
sigfilter 30 a+e  &  270.0~M &  7.0~GB & 0.2857 & 0.2976 \\
eppex 1:n+1       &  127.9~M &  3.2~GB & 0.2859 & 0.2953 \\
eppex 2:n+2       &   77.0~M &  2.0~GB & 0.2839 & 0.2943 \\
\hline
\end{tabular}
\caption{\label{fr-en-pt-size-and-bleu}
Phrase table sizes and BLEU scores for various experiments of "Fr-En" setup.}
\end{table}

...

\subsection{Memory and time requirements}

\Tref{fr-en-time-benchmarks} presents the amount of time necessary to finish
phrase table extraction with various systems and their configurations.

% Fr-En: baseline and eppex wall clock and CPU time values
\begin{table}[ht]
\centering
\begin{tabular}{ | c | r r | r r | r r | }
\hline
 & \multicolumn{2}{|c|}{total time} & \multicolumn{2}{|c|}{extraction} & \multicolumn{2}{|c|}{scoring} \\
experiment & wall & CPU & wall & CPU & wall & CPU \\
\hline
\hline
opt-base      & 56.8 & 146.1 & 15.0 & 39.2 & 41.8 & 106.9 \\
opt-c8-base   & 45.1 & 149.8 & 12.7 & 39.7 & 32.4 & 110.1 \\
eppex zero    & 25.5 &  25.4 & -- & -- & -- & -- \\
\hline
eppex def.    & 12.2 & 12.2 & -- & -- & -- & -- \\
eppex zero-n  & 10.7 & 10.7 & -- & -- & -- & -- \\
eppex 1:n+1   & 9.5 & 9.5 & -- & -- & -- & -- \\
eppex 2:n+2   & 9.3 & 9.2 & -- & -- & -- & -- \\
\hline
\end{tabular}
\caption{\label{fr-en-time-benchmarks}
Wallclock times and CPU usage values (in hours) of the phrase table
construction for various experiments of "Fr-En" setup.}
\end{table}

...

\Tref{fr-en-vm-and-disk-usage-peaks} illustrates both memory and disk space demands of baseline
and \eppex{} experiments.

% Fr-En: virtual memory and disk usage peaks
\begin{table}[ht]
\centering
\begin{tabular}{ | c | r l | r | }
\hline
 & \multicolumn{2}{|c|}{VM peak} & \\
experiment & size & step & du peak \\
\hline
\hline
opt-base       & 200.1~GB & extraction & 160.5~GB \\
opt-c8-base    & 200.1~GB & extraction & 160.5~GB \\
eppex zero     & 203.0~GB &      eppex &  48.0~GB \\
\hline
eppex def.     &  89.9~GB &      eppex &  16.0~GB \\
eppex zero-n   &  48.7~GB &      eppex &   8.0~GB \\
eppex 1:n+1    &  46.4~GB &      eppex &   4.0~GB \\
eppex 2:n+2    &  45.6~GB &      eppex &   2.0~GB \\
\hline
\end{tabular}
\caption{\label{fr-en-vm-and-disk-usage-peaks}
Virtual memory and disk usage peaks of the phrase table construction for various experiments of "Fr-En" setup.}
\end{table}

...

Finally, \Tref{fr-en-sigfilter-runtime-benchmarks} presents the runtime benchmarking
values for different runs of significance filtering.\footnote{Due a tight experiments
schedule we run the significance filtering experiments on Fr-En setup on the set of
machines designated for Cs-En setup.}

% TODO: Any comment?

% Fr-En: sigfilter runtime requirements
\begin{table}[ht]
\centering
\begin{tabular}{ | c | r r | r l | }
\hline
 & \multicolumn{2}{|c|}{time} & \multicolumn{2}{|c|}{VM peak} \\
experiment & wall & CPU & size & step \\
\hline
\hline
sigfilter a-e     & 82.7~h & 87.9~h & 28.2~GB & filtering \\
sigfilter a+e     & 83.9~h & 87.2~h & 28.5~GB & filtering \\
sigfilter 30 a+e  & 46.9~h & 50.3~h & 28.4~GB & filtering \\
sigfilter 30      & 10.3~h & 13.8~h & 11.5~GB & indexing \\
\hline
\end{tabular}
\caption{\label{fr-en-sigfilter-runtime-benchmarks}
Wallclock times and CPU usage values, virtual memory peak value and the step,
in which it occurred, of significance filtering for various settings of \emph{sigfilter} in "Fr-En" setup.}
\end{table}

\section{Comparison to 2011 version}
\label{sec:cu-bojar-results}
% Comparison of current eppex and phrase-extract performance vs. mid-2011 state

\citet{przywara:eppex} presented an evaluation of an early version of \eppex{}
that was able to only extract phrases. It performed a faster phrase
table creation than the legacy \emph{phrase-extract} in such situations,
where lossy counting resulted in significant filtration of extracted phrase
pairs and consequent sub-steps (sorting, scoring and consolidation of both
phrase table halves) had to process reduced amount of data;
eventually the whole process of phrase table creation finished faster.

As we had all the parallel data used in their experiments available and
we perform our runtime benchmarking in almost identical manner,
we decided to carry out comparison between the early and current versions of
both \eppex{} as well as \emph{phrase-extract} toolkit.

\subsection{Implementation differences}

The current version of \eppex{} differs from the early version mainly in the
capability of performing not only phrase pairs extraction, but a complete
phrase table construction (that is including phrase pairs scoring).
The early version, however, could be used to extract orientation info
the same way \emph{extract} can, while this functionality has been dropped
from the current version as not related to the core task of phrase table creation.
Following the upgrade of \emph{phrase-extract} suite, an option to read from
gzipped input files and dump gzipped output files has been added to \eppex{}.
Internally, there have been a multitude of performance tweaks,
as performance optimization is the most important aim in \eppex{} development,
but a full listing of implementation changes would be purposeless here.

On the contrary, \emph{phrase-extract} suite has been updated mainly in order to
provide a richer functionality, but three changes since the mid-2011 version
had a sound impact on its runtime performance: the optimization of target phrases
scanning in the \emph{scorer} implementation,\footnote{Commit 677378774aca30c8f0d4ca57267f7ac5ef7d7cb6.}
adding an option to gzip the output directly within the main three binaries
(\emph{extract}, \emph{scorer} and \emph{consolidate})
and the parallelization of both phrase extraction and phrase scoring
steps.\footnote{See \texttt{extract-parallel.perl} and \texttt{score-parallel.perl}
in \texttt{<moses>/scripts/generic/}.}

\subsection{Parameters of experiments}

\Tref{cu-bojar-scenarios} presents all the experiments and their settings.
Again, we have included one more optimized baseline with 7 cores, because
the achieved speeding up is considerable.
The \emph{default baseline} is invoked with the same parameters as the \emph{2011
baseline}, except for an option that turns on gzipping of temporary data and
phrase table that is now implicitly activated from within the training script.
Because of this, we also turn \verb|--GZOutput| on for all \eppex{} runs.
We experimented with different pruning parameters: \emph{eppex-1-in} (milder
pruning) and \emph{eppex-1-out} (harsher pruning) are using the same pruning
parameters as the 2011 experiments and we also performed \emph{eppex zero}
experiment (an \eppex{} run with no pruning).

% Detailed info of cu-bojar experiments
\begin{table}[ht]
\centering
\begin{tabular}{ r p{10cm} }
name & description and parameters \\
\hline
\hline
def-base        & Standard Moses pipeline with no special parameters \\
multi-base      & Standard Moses pipeline with \verb|--cores 4| \\
comp-base       & Standard Moses pipeline with \verb|--sort-compress gzip|
  and \verb|--cores 4| \\
opt-base        & Standard Moses pipeline with \verb|--sort-buffer 12G|,
  \verb|--sort-compress gzip| and \verb|--cores 4| \\
opt-c7-base     & Standard Moses pipeline with \verb|--sort-buffer 12G|,
  \verb|--sort-compress gzip| and \verb|--cores 7| \\
eppex zero      & \eppex{} set to no pruning and \verb|--GZOutput| option \\
eppex 1-in      & \eppex{} with pruning thresholds set to keep in
  all phrase pairs of length 1--3 and prune longer phrase pairs
  with max. positive threshold of 8 and \verb|--GZOutput| option \\
eppex 1-out     & \eppex{} with pruning thresholds set to remove
  all single-occurring phrase pairs and prune the rest with
  max. positive threshold of 8 and \verb|--GZOutput| option \\
\hline
\hline
\end{tabular}
\caption{\label{cu-bojar-scenarios}List of various experiments and their
settings for "cu-bojar" setup. The parameters of "eppex 1-in" and "eppex 1-out"
conform to the corresponding 2011 experiments, "def-base" corresponds to the 2011
"baseline" experiment except for (now activated implicitly) gzipping of
temporary data.}
\end{table}

\subsection{Memory and time requirements}

% NOTE:
% Steps and substeps of phrase table construction via train-model.perl back in 2011:
% (1) Phrase extraction
%  a) extract
%  b) gzip f2e
%  c) gzip e2f
% (2) Phrase scoring
%  d) sort f2e (now done in (1) and so reported as part of phrase extraction in table below)
%  e) score e2f
%  f) sort e2f (now done in (1) and so reported as part of phrase extraction in table below)
%  g) score e2f
%  h) sort inv
%  i) cons
%  j) gzip pt

\Tref{cu-bojar-time-benchmarks} compares wallclock times and CPU usage of all the
experiments and in case of baseline and 2011 experiments also separately for phrase
extraction and phrase scoring steps.

The comparison between the old and current baselines reveals that the optimization of
\emph{scorer} mentioned above resulted in a speed up by more than a factor of two.
On the other hand the default phrase extraction became slightly more time demanding,
but this may be explained by the fact that parallelization incurred some overhead
that does not pay back when running only with a single core, but significantly cuts
down the running time when using multiple cores: in our setup using 7~cores (along with
more memory for sorting) lowered time of phrase extraction to 40\% and of phrase scoring
to almost 50\% of respective default measures.

The comparison between 2011 and current version of \eppex{} also displays a significant
speed up: with harsh pruning the phrase table construction is done in half an hour (took
almost two hours in 2011) and without any pruning the full phrase table was built in
less than hour and half, thus \eppex{} proves to be a viable alternative to
\emph{phrase-extract} also in situations, when pruning is not an option (being twice as
fast than the optimized baseline).

\begin{table}[ht]
\centering
\begin{tabular}{ | c | r r | r r | r r | }
\hline
 & \multicolumn{2}{|c|}{total time} & \multicolumn{2}{|c|}{extraction} & \multicolumn{2}{|c|}{scoring} \\
experiment & wall & CPU & wall & CPU & wall & CPU \\
\hline
\hline
baseline*     & 8.8 & 7.1 & 2.1 & 1.0 & 6.7 & 6.1 \\
def-base      & 5.6 & 4.8 & 2.5 & 1.5 & 3.1 & 3.2 \\
multi-base    & 4.3 & 5.7 & 2.2 & 1.5 & 2.1 & 4.1 \\
comp-base     & 3.3 & 7.1 & 1.1 & 2.5 & 2.3 & 4.6 \\
opt-base      & 3.2 & 6.0 & 1.1 & 1.7 & 2.1 & 4.3 \\
opt-c7-base   & 2.8 & 6.0 & 1.1 & 1.6 & 1.7 & 4.3 \\
eppex zero    & 1.4 & 1.4 & -- & -- & -- & -- \\
\hline
eppex 1-in*   & 4.1 & 3.7 & 1.8 & 1.5 & 2.2 & 2.2 \\
eppex 1-in    & 0.8 & 0.8 & -- & -- & -- & -- \\
\hline
eppex 1-out*  & 1.8 & 1.6 & 1.6 & 1.4 & 0.2 & 0.2 \\
eppex 1-out   & 0.5 & 0.5 & -- & -- & -- & -- \\
\hline
\end{tabular}
\caption{\label{cu-bojar-time-benchmarks}
Wallclock times and CPU usage values (in hours) of the phrase table
construction for various experiments of "cu-bojar" setup.
Asterisk denotes the particular measures from 2011 experiments.}
\end{table}

\Tref{cu-bojar-vm-and-du-peaks} presents memory and disk usage peaks of all the experiments
(except for disk usage peaks that are not available for 2011 experiments).

Memory demands of the baseline remain low, the 0.1~GB difference between 2011 and now
stems from the fact that our benchmarking script includes the main process into the set of
measured processes.
An optimized baseline is the most memory demanding, but this is only because we assigned 12~GB
of RAM to the sorting processes and both phrase table halves are sorted simultaneously after
phrase extraction.

Memory demands of the current version of \eppex{} are significantly lower than of the 2011 version:
in 2011, the harsh pruning setup required as much memory as the current version run without
any pruning at all.

The disk peak usage is significantly reduced in \emph{compressed} baseline, but rises almost to
default levels in optimized baselines, despite the \verb|--sort-compress| option has been applied
to them as well.
We do not poses sufficient knowledge of the inner workings of \emph{GNU sort}, therefore we do not
attempt to give an explanation of this peculiar behavior.

\begin{table}[ht]
\centering
\begin{tabular}{ | c | r | r | }
\hline
experiment & VM peak & du peak \\
\hline
\hline
baseline*     &  1.1~GB &      -- \\
def-base      &  1.2~GB & 51.8~GB \\
multi-base    &  3.9~GB & 53.6~GB \\
comp-base     &  3.9~GB & 14.3~GB \\
opt-base      & 24.1~GB & 43.7~GB \\
opt-c7-base   & 24.1~GB & 43.7~GB \\
eppex zero    & 16.8~GB &  3.7~GB \\
\hline
eppex 1-in*   & 19.2~GB &      -- \\
eppex 1-in    & 13.4~GB &  1.3~GB \\
\hline
eppex 1-out*  & 16.7~GB &      -- \\
eppex 1-out   & 11.3~GB &  0.3~GB \\
\hline
\end{tabular}
\caption{\label{cu-bojar-vm-and-du-peaks}
Virtual memory and disk usage peaks of the phrase table construction for various experiments
of "cu-bojar" setup. Asterisk denotes the particular measures from 2011 experiments.}
\end{table}

\section{Eppex and memory demands}
\label{sec:eppex-memory-demands}

We performed an additional series of experimental phrase table extractions with
the Cs-En and Fr-En datasets to get an insight on the impact of training data size and
values of pruning limits on memory demands of \eppex{} and the amount of phrase pairs
extracted.

For both datasets we created a list of input size cuts and then with each cut of size $K$
we did the following:
\begin{enumerate}
  \item From the first $K$ sentences of the whole dataset and their word alignments, we
    created a temporary training dataset.
  \item Using Moses \texttt{train-model.perl} script, we constructed lexical scores tables
    from the temporary training data.\footurl{http://www.statmt.org/moses/?n=FactoredTraining.GetLexicalTranslationTable}
  \item Finally, we used the temporary training data and lexical scores tables to perform several epochal
    extractions with some of the configurations mentioned in
    \Sref{sec:cs-en-results} (for Cs-En cuts) and \Sref{sec:fr-en-results} (for Fr-En cuts).
    We measured the virtual memory peak and recorded phrase table size of each extraction.
\end{enumerate}

\subsection{Fr-En dataset}

Our French-English training data contained only a single factor: a lowercased token.
There was in average 30 French and 25.5 English tokens per sentence in the whole data,
but in most of the cuts these averages were lower (down to 25.5 tokens per sentence
in case of French and 24 tokens per sentence in case of English).

\Tref{fr-en-memory-benchmarking} presents the comparison of virtual memory peaks
of several \eppex{} configurations described in \Sref{sec:fr-en-results}, while
\Tref{fr-en-output-size-benchmarking} presents corresponding phrase table sizes obtained.

% Memory benchmarking table for Fr-En
\begin{table}[ht]
\centering
\begin{tabular}{ | r | r | r | r | r | r | r | r | }
\hline
\multicolumn{3}{|c|}{input data size} & \multicolumn{5}{|c|}{virtual memory peak per eppex configuration} \\
\hline
sent. & source & target & zero & def. & zero-n & 1:n+1 & 1:n+2 \\
\hline
\hline
.1~M & 2.6~M & 2.4~M & 0.9~GB & 0.4~GB & 0.3~GB & 0.2~GB & 0.2~GB \\
.2~M & 5.1~M & 4.8~M & 1.7~GB & 0.8~GB & 0.4~GB & 0.4~GB & 0.3~GB \\
.3~M & 7.7~M & 7.2~M & 2.5~GB & 1.2~GB & 0.6~GB & 0.6~GB & 0.5~GB \\
.4~M & 10.2~M & 9.6~M & 3.2~GB & 1.5~GB & 0.8~GB & 0.8~GB & 0.6~GB \\
.5~M & 12.8~M & 12.1~M & 4.0~GB & 2.0~GB & 1.0~GB & 0.9~GB & 0.7~GB \\
.6~M & 15.5~M & 14.5~M & 5.0~GB & 2.3~GB & 1.2~GB & 1.1~GB & 0.9~GB \\
.7~M & 18.2~M & 16.9~M & 5.7~GB & 2.6~GB & 1.4~GB & 1.3~GB & 1.0~GB \\
.8~M & 21.0~M & 19.3~M & 6.4~GB & 3.0~GB & 1.6~GB & 1.4~GB & 1.2~GB \\
.9~M & 23.7~M & 21.8~M & 7.1~GB & 3.4~GB & 1.8~GB & 1.7~GB & 1.3~GB \\
1~M & 26.6~M & 24.3~M & 7.8~GB & 3.8~GB & 2.0~GB & 1.8~GB & 1.4~GB \\
\hline
2~M & 53.6~M & 48.4~M & 15.4~GB & 7.4~GB & 3.8~GB & 3.4~GB & 2.6~GB \\
3~M & 80.2~M & 72.3~M & 23.6~GB & 10.4~GB & 5.5~GB & 5.0~GB & 3.9~GB \\
4~M & 109.3~M & 98.8~M & 29.7~GB & 13.6~GB & 7.0~GB & 6.5~GB & 5.1~GB \\
5~M & 138.5~M & 125.2~M & 35.0~GB & 15.7~GB & 8.5~GB & 7.9~GB & 6.2~GB \\
6~M & 165.6~M & 148.1~M & 42.4~GB & 18.0~GB & 9.8~GB & 9.1~GB & 7.3~GB \\
7~M & 193.3~M & 171.2~M & 46.3~GB & 20.1~GB & 10.7~GB & 10.1~GB & 8.1~GB \\
8~M & 222.3~M & 195.2~M & 50.8~GB & 21.6~GB & 11.6~GB & 10.8~GB & 9.1~GB \\
9~M & 251.4~M & 219.3~M & 55.3~GB & 23.7~GB & 12.6~GB & 11.8~GB & 9.9~GB \\
10~M & 279.4~M & 242.1~M & 59.6~GB & 25.4~GB & 13.9~GB & 13.0~GB & 10.6~GB \\
\hline
12~M & 338.2~M & 291.1~M & 69.1~GB & 29.1~GB & 16.0~GB & 14.8~GB & 12.4~GB \\
14~M & 398.3~M & 341.4~M & 84.3~GB & 34.8~GB & 18.9~GB & 17.5~GB & 14.2~GB \\
16~M & 458.2~M & 391.4~M & 93.8~GB & 39.7~GB & 21.1~GB & 19.4~GB & 16.0~GB \\
18~M & 519.1~M & 442.3~M & 103~GB & 44.2~GB & 23.6~GB & 21.8~GB & 17.6~GB \\
20~M & 580.8~M & 493.9~M & 113~GB & 48.4~GB & 25.8~GB & 23.7~GB & 19.1~GB \\
\hline
25~M & 749.3~M & 636.4~M & 141~GB & 61.5~GB & 33.1~GB & 30.2~GB & 25.3~GB \\
30~M & 903.5~M & 768.7~M & 174~GB & 73.6~GB & 38.8~GB & 36.1~GB & 30.5~GB \\
35~M & 1050~M & 895.1~M & 190~GB & 85.5~GB & 44.9~GB & 42.6~GB & 35.1~GB \\
full & 1173~M & 1001~M & 203~GB & 89.9~GB & 48.7~GB & 46.4~GB & ??.?~GB \\ % TODO: Fill in missing value.
\hline
\end{tabular}
\caption{\label{fr-en-memory-benchmarking}
Virtual memory peaks of the phrase table construction performed with
various configurations of \eppex{} on portions of "Fr-En" dataset.
The input data size triple stands for: number of parallel sentences and number of words on the source and target side.
The full corpus had more than 39~M of parallel sentences.}
\end{table}

% TODO: Comment on the memory probing.
...

% Output size benchmarking table for Fr-En
\begin{table}[ht]
\centering
\begin{tabular}{ | r | r | r | r | r | r | r | r | }
\hline
\multicolumn{3}{|c|}{input data size} & \multicolumn{5}{|c|}{phrase table size per eppex configuration} \\
\hline
sent. & source & target & zero & def. & zero-n & 1:n+1 & 1:n+2 \\
\hline
\hline
.1~M & 2.6~M & 2.4~M & 7.7~M & 2.8~M & 1.6~M & 237~K & 182~K \\
.2~M & 5.1~M & 4.8~M & 14.8~M & 5.2~M & 3.0~M & 471~K & 362~K \\
.3~M & 7.7~M & 7.2~M & 22.0~M & 7.5~M & 4.4~M & 695~K & 531~K \\
.4~M & 10.2~M & 9.6~M & 29.3~M & 10.0~M & 5.9~M & 940~K & 719~K \\
.5~M & 12.8~M & 12.1~M & 36.8~M & 12.5~M & 7.4~M & 1.2~M & 891~K \\
.6~M & 15.5~M & 14.5~M & 44.1~M & 14.9~M & 8.8~M & 1.4~M & 1.1~M \\
.7~M & 18.2~M & 16.9~M & 51.2~M & 17.2~M & 10.1~M & 1.7~M & 1.3~M \\
.8~M & 21.0~M & 19.3~M & 58.3~M & 19.4~M & 11.4~M & 2.0~M & 1.5~M \\
.9~M & 23.7~M & 21.8~M & 65.3~M & 21.6~M & 12.6~M & 2.3~M & 1.7~M \\
1~M & 26.6~M & 24.3~M & 72.5~M & 23.9~M & 14.1~M & 2.5~M & 1.9~M \\
\hline
2~M & 53.6~M & 48.4~M & 142.1~M & 44.7~M & 27.1~M & 4.9~M & 3.7~M \\
3~M & 80.2~M & 72.3~M & 211.1~M & 64.7~M & 39.9~M & 7.2~M & 5.6~M \\
4~M & 109.3~M & 98.8~M & 270.3~M & 78.7~M & 44.1~M & 10.1~M & 8.0~M \\
5~M & 138.5~M & 125.2~M & 322.0~M & 88.5~M & 49.7~M & 12.7~M & 10.1~M \\
6~M & 165.6~M & 148.1~M & 367.8~M & 102.1~M & 60.4~M & 17.9~M & 15.0~M \\
7~M & 193.3~M & 171.2~M & 406.8~M & 114.7~M & 66.6~M & 25.5~M & 22.2~M \\
8~M & 222.3~M & 195.2~M & 450.6~M & 127.1~M & 81.1~M & 30.2~M & 25.7~M \\
9~M & 251.4~M & 219.3~M & 495.3~M & 141.5~M & 90.1~M & 36.5~M & 30.8~M \\
10~M & 279.4~M & 242.1~M & 538.9~M & 154.3~M & 103.6~M & 40.2~M & 34.0~M \\
\hline
12~M & 338.2~M & 291.1~M & 632.4~M & 179.3~M & 123.2~M & 44.3~M & 36.0~M \\
14~M & 398.3~M & 341.4~M & 726.8~M & 203.5~M & 141.6~M & 46.8~M & 37.3~M \\
16~M & 458.2~M & 391.4~M & 819.8~M & 225.4~M & 158.6~M & 49.3~M & 38.9~M \\
18~M & 519.1~M & 442.3~M & 913.2~M & 247.8~M & 176.5~M & 53.2~M & 41.9~M \\
20~M & 580.8~M & 493.9~M & 1007~M & 270.7~M & 195.4~M & 57.8~M & 45.5~M \\
\hline
25~M & 749.3~M & 636.4~M & 1290~M & 349.2~M & 268.0~M & 70.6~M & 55.1~M \\
30~M & 903.5~M & 768.7~M & 1502~M & 401.4~M & 269.1~M & 90.6~M & 72.9~M \\
35~M & 1050~M & 895.1~M & 1659~M & 437.9~M & 269.7~M & 110.8~M & 91.1~M \\
full & 1173~M & 1001~M & 1782~M & 463.4~M & 283.2~M & 127.9~M & ??.?~M \\ % TODO: Fill in missing value.
\hline
\end{tabular}
\caption{\label{fr-en-output-size-benchmarking}
Phrase table sizes (in phrase pairs) obtained with various configurations of \eppex{}
on portions of "Fr-En" dataset. The input data size triple stands for: number of
parallel sentences and number of words on the source and target side.
The full corpus had more than 39~M of parallel sentences.}
\end{table}

% TODO: Comment on phrase table sizes.
...
